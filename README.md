# üß† Interpreting NLP Models: A Stability and Explainability Comparison of BERT and Logistic Regression

*A Stability and Interpretability Study in NLP*

[![Quarto Book](https://img.shields.io/badge/Quarto-Book-blue?logo=quarto)](https://rain-shi.github.io/lime-nlp-stability/)

---

## üìò Project Overview

This project investigates the **interpretability** and **stability** of two model explanation techniques ‚Äî **LIME** and **SHAP** ‚Äî applied to both a **TF-IDF + Logistic Regression** model and a **fine-tuned BERT** classifier. We use the Twitter Entity Sentiment dataset to evaluate how model complexity impacts the transparency of predictions and how robust these explanations are under input perturbations.

---

## üìÇ Project Structure

| File                 | Description                                                               |
| -------------------- | ------------------------------------------------------------------------- |
| `index.qmd`          | Project introduction, goals, and structure overview                       |
| `data.qmd`           | Loads and explores the training/validation dataset                        |
| `modeling.qmd`       | Builds the TF-IDF + Logistic Regression classifier                        |
| `bert_modeling.qmd`  | Fine-tunes and evaluates a BERT model for sentiment classification        |
| `lime_logistics.qmd` | Applies LIME to the logistic regression model                             |
| `lime_bert.qmd`      | Applies LIME to the BERT model                                            |
| `shap_logistics.qmd` | Explains logistic regression using SHAP (KernelExplainer)                 |
| `shap_bert.qmd`      | Applies SHAP to the BERT classifier                                       |
| `perturbation.qmd`   | Tests explanation stability using synonym substitutions and Jaccard score |
| `conclusion.qmd`     | Summarizes findings and provides reflections and future directions        |

---

## üõ† Setup & Usage

### 1. Clone the Repository

```bash
git clone https://github.com/Rain-Shi/lime-nlp-stability.git
cd lime-nlp-stability
```

### 2. Create Virtual Environment & Install Dependencies

```bash
python -m venv .venv
source .venv/bin/activate        # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Render the Quarto Book

```bash
quarto render
```

### 4. Preview in Browser

Rendered outputs will be in the `docs/` folder and can be viewed locally or hosted online.

üîó [https://rain-shi.github.io/lime-nlp-stability](https://rain-shi.github.io/lime-nlp-stability)

---

## üì¶ Dataset

We use the [Twitter Entity Sentiment Analysis dataset](https://www.kaggle.com/competitions/twitter-entity-sentiment-analysis) which contains tweets labeled with:

* `id`: Unique identifier
* `entity`: Entity referenced in the tweet (e.g., person or organization)
* `sentiment`: Sentiment label (`Positive`, `Neutral`, `Negative`)
* `tweet`: Raw tweet text

---

## üîç Research Questions

* Can LIME and SHAP generate coherent explanations on noisy, informal tweets?
* How does model complexity (BERT vs. Logistic Regression) affect interpretability?
* Are explanations consistent under small input perturbations?
* How do bar plots and word clouds support human interpretation of models?

---

## üìà Learning Outcomes

Through this project, you‚Äôll learn:

* How to fine-tune BERT for text classification
* How to apply LIME and SHAP to explain model predictions
* How to evaluate explanation stability using controlled perturbations
* How to visualize and compare interpretability outputs
* How to deploy Quarto books as structured, interactive NLP reports

---

## üîó Credits

This project was developed for the final project of **GR5293: Exploratory Data Analysis and Visualization** at Columbia University.

Special thanks to [Prof. Joyce Robbins](https://www.jtr13.com/) and the EDAV team.
Inspired by the [LIME paper](https://arxiv.org/abs/1602.04938) and [Twitter dataset on Kaggle](https://www.kaggle.com/competitions/twitter-entity-sentiment-analysis).

---

