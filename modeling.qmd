---
title: "TF_IDF+Logistic Regression Modeling"
format: html
jupyter: python3
---

## Objective

We aim to build a **baseline text classification model** that predicts the **sentiment** toward a given **entity** in a tweet.

The model performs **4-class classification**, identifying whether the sentiment is Positive, Negative, Neutral, or Irrelevant.
---

## Baseline: Logistic Regression with TF-IDF
In this step, we build a baseline sentiment classification model using a Scikit-learn pipeline that combines:

TF-IDF Vectorization: Converts tweets into numeric features based on word frequency and inverse document frequency. Specifically, we:

Remove English stopwords

Limit vocabulary to the top 10,000 terms

Use unigrams and bigrams (1â€“2-gram)

Logistic Regression Classifier: A linear model used for multi-class classification.

max_iter=1000 ensures convergence for larger feature sets.

The dataset is split into an 80/20 train-test split.
We evaluate the model using the classification_report function, which reports precision, recall, and F1-score for each sentiment class.
```{python}
# Load & Preprocess Data
import pandas as pd
from sklearn.model_selection import train_test_split

col_names = ["id", "entity", "sentiment", "tweet"]

train = pd.read_csv("data/twitter_training.csv", header=None, names=col_names)
train = train.dropna(subset=["tweet"])
train = train[train["tweet"].str.strip().astype(bool)]
X = train["tweet"]
y = train["sentiment"]
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

model = make_pipeline(
    TfidfVectorizer(stop_words='english',max_features=10000, ngram_range=(1,2)),
    LogisticRegression(max_iter=1000)
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))
```

## Save Trained Model for Interpretation
After training, we save the entire pipeline (including the TF-IDF vectorizer and the logistic regression classifier) using joblib. This serialized model will be used later for interpretability analysis with tools like LIME or SHAP.
```{python}
import joblib

# Save pipeline
joblib.dump(model, "scripts/baseline_pipeline.pkl")
```


