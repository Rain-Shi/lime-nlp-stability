---
title: "Dataset Overview"
format: html
jupyter: python3
---

## Dataset Description

This project uses the **Twitter Entity Sentiment Analysis** dataset. It consists of two files:

-   `twitter_training.csv`: Main training dataset\
-   `twitter_validation.csv`: Validation dataset

Each row contains: - an **ID** - a **target entity** - the **sentiment label**: `Positive`, `Neutral`, `Negative, or  Irrelevant` - a **tweet**

The task is to predict the sentiment expressed toward the entity.

------------------------------------------------------------------------

## Sample Records (Training Set)

We display a few sample records from the training set to get a sense of what the tweets and associated sentiment labels look like. This is helpful for qualitative understanding of the input data before preprocessing.

```{python}
import pandas as pd

# Define column names
col_names = ["id", "entity", "sentiment", "tweet"]

# Load CSVs with no header row
train = pd.read_csv("data/twitter_training.csv", header=None, names=col_names)
valid = pd.read_csv("data/twitter_validation.csv", header=None, names=col_names)

train.sample(5)[["tweet", "entity", "sentiment"]]
```

## Data Cleaning

The dataset is used to train and evaluate sentiment classification models.

### Delete Missing Data

In this step, we remove rows with missing or empty tweet texts to ensure clean inputs for training.

```{python}

# Remove rows with missing or empty tweets
print(train.isnull().sum())

train = train.dropna(subset=["tweet"])
train = train[train["tweet"].str.strip().astype(bool)]
```

### Delete Missing Emoji

In this step, we remove emojis from tweets to clean the text and ensure consistent tokenization for vectorization. Here is the  examples: 

```{python}
import emoji

# Define cleaning function
def clean_text(text):
    no_emoji = emoji.replace_emoji(text, replace='')
    return no_emoji.encode("utf-8", "ignore").decode("utf-8", "ignore")

# Apply to training set
train["tweet"] = train["tweet"].apply(clean_text)

#ourexample
samples = [
    "I'm so happy today! ğŸ˜„ğŸ‰",
    "Great job! ğŸ’¯ğŸ”¥",
    "This is weird... ğŸ¤”ğŸ™ƒ",
    "Just finished my code ğŸğŸ’»"
]

max_len = max(len(s) for s in samples)

for s in samples:
    cleaned = clean_text(s)
    print(f"{s.ljust(max_len)}  â†’  {cleaned}")

```

## Basic Statistics

We explore the basic statistics of the dataset, including class distributions and dataset sizes. This helps us understand potential class imbalance and verify the dataset was loaded correctly.

```{python}
sentiment_counts = train["sentiment"].value_counts().reset_index()
sentiment_counts.columns = ["Sentiment", "Count"]
sentiment_counts.index.name = "Index"

sentiment_counts.style.set_table_styles(
    [{"selector": "th", "props": [("text-align", "center")]}]
).set_properties(**{
    'text-align': 'center',
    'border': '1px solid lightgrey',
    'background-color': '#f9f9f9'
}).hide(axis="index")


```

We explore the basic statistics of the dataset, including class distributions and dataset sizes. This helps us understand potential class imbalance and verify the dataset was loaded correctly.\
Based on the distribution of sentiment labels, we did **not observe a significant class imbalance** in the dataset.

## Sentiment Distribution (Bar-Chart)

```{python}
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.countplot(data=train, x="sentiment")
plt.title("Sentiment Distribution in Training Set")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.grid(True)
plt.tight_layout()
plt.show()

```
