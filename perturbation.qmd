---
title: "Perturbation Stability: Comparing LIME and SHAP for Logistic Regression and BERT"
format: html
jupyter: python3
---

## Goal

This notebook compares the **stability of explanation methods** under text perturbations across two models:

- **TF-IDF + Logistic Regression** (interpretable baseline)  
- **Fine-tuned BERT** (context-aware deep model)

We evaluate robustness of two explainability tools:
- **LIME**: Local Interpretable Model-Agnostic Explanations  
- **SHAP**: SHapley Additive exPlanations

Using:
- Overall top words  
- Word clouds  
- Perturbation robustness via **Jaccard similarity**

---

##Overall Top Words (Barplot)

### LIME - BERT
![](https://rain-shi.github.io/lime-nlp-stability/lime_bert_files/figure-html/cell-6-output-1.png)

### LIME - Logistic Regression
![](https://rain-shi.github.io/lime-nlp-stability/lime_logistics_files/figure-html/cell-5-output-1.png)

### SHAP - BERT
![](https://rain-shi.github.io/lime-nlp-stability/shap_bert_files/figure-html/cell-6-output-1.png)

### SHAP - Logistic Regression
![](https://rain-shi.github.io/lime-nlp-stability/shap_logistics_files/figure-html/cell-5-output-1.png)

---

## Word Cloud Comparison

### LIME - BERT
![](https://rain-shi.github.io/lime-nlp-stability/lime_bert_files/figure-html/cell-7-output-1.png)

### LIME - Logistic Regression
![](https://rain-shi.github.io/lime-nlp-stability/lime_logistics_files/figure-html/cell-6-output-1.png)

### SHAP - BERT
![](https://rain-shi.github.io/lime-nlp-stability/shap_bert_files/figure-html/cell-6-output-1.png)

### SHAP - Logistic Regression
![](https://rain-shi.github.io/lime-nlp-stability/shap_logistics_files/figure-html/cell-5-output-1.png)

---

## Perturbation Stability (Jaccard Similarity)

| Method | Model               | Avg. Jaccard Similarity | Stability Rank |
|--------|---------------------|--------------------------|----------------|
| LIME   | Logistic Regression | **0.675**                | ✅ Higher      |
| LIME   | BERT                | 0.473                    | ❌ Lower       |
| SHAP   | Logistic Regression | **~0.67**                | ✅ Higher      |
| SHAP   | BERT                | ~0.48                    | ❌ Lower       |

## Summary

- **Interpretability**: Logistic Regression highlights more literal, general words (e.g., *fix*, *sad*, *recommend*), while BERT focuses on context-dependent or emotional cues.
- **Consistency**: Both SHAP and LIME show **reduced stability on BERT**, with Jaccard drops > 0.15 compared to logistic models.
- **Takeaway**: There is a clear **trade-off between model complexity and explanation robustness**, regardless of the explanation method used.

